{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def consecutive_bool(data, stepsize=1):\n",
    "    return np.split(data, np.where(np.diff(data) != stepsize)[0]+1)\n",
    "\n",
    "# set manual parameters\n",
    "window_pts = 70\n",
    "len_lim = 3\n",
    "dt_loc_thresh = 550\n",
    "loc_it = 4\n",
    "\n",
    "parentdir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resave MINFLUX datasets exported as npy files (old abberior file format, pre-2025-06) as files readable by PYME, for eventual 3D surface fitting from localization clouds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e1\n",
      "e1-ROI0-cycle0.csv\n",
      "e1-ROI0-cycle1.csv\n",
      "e1-ROI0-cycle2.csv\n",
      "e1-ROI0-cycle3.csv\n",
      "e1-ROI0-cycle4.csv\n",
      "e1-ROI0-cycle5.csv\n",
      "e1-ROI0-cycle6.csv\n",
      "e1-ROI0-cycle7.csv\n",
      "e2\n",
      "e2-ROI0-cycle0.csv\n",
      "e2-ROI0-cycle1.csv\n",
      "e2-ROI0-cycle2.csv\n",
      "e2-ROI0-cycle3.csv\n",
      "e2-ROI0-cycle4.csv\n"
     ]
    }
   ],
   "source": [
    "topfolder = os.path.join(parentdir, 'exampledata\\\\dyn1\\\\241101\\\\sample1\\\\cell2')\n",
    "\n",
    "folders = os.listdir(topfolder)\n",
    "folders = [folder for folder in folders if 'manual' not in folder]\n",
    "roi_name = 'ROI0'\n",
    "\n",
    "for folder in folders:\n",
    "    print(folder)\n",
    "    folder_date = folder.split('-')[0]\n",
    "    filelist_all = os.listdir(os.path.join(topfolder,folder))\n",
    "    filelist_npy = [file for file in filelist_all if file.endswith('.npy') and roi_name in file]\n",
    "    for cycle, file in enumerate(filelist_npy):\n",
    "        savename = f'{folder_date}-{roi_name}-cycle{cycle}.csv'\n",
    "        print(savename)\n",
    "        \n",
    "        file = os.path.join(topfolder,folder,file)\n",
    "        dataset = np.load(file)\n",
    "        \n",
    "        # get all (x,y,z) coodinates\n",
    "        x = np.zeros((len(dataset),1))\n",
    "        y = np.zeros((len(dataset),1))\n",
    "        z = np.zeros((len(dataset),1))\n",
    "        z1 = np.zeros((len(dataset),1))\n",
    "        tid = np.zeros((len(dataset),1))\n",
    "        tim = np.zeros((len(dataset),1))\n",
    "        efo = np.zeros((len(dataset),1))\n",
    "        for i in range(len(dataset)):\n",
    "            x[i] = dataset[i][0][loc_it][2][0]\n",
    "            y[i] = dataset[i][0][loc_it][2][1]\n",
    "            z[i] = dataset[i][0][loc_it][2][2]\n",
    "            z1[i] = dataset[i][0][1][2][2]\n",
    "            efo[i] = dataset[i][0][loc_it][6]\n",
    "            tid[i] = dataset[i][4]\n",
    "            tim[i] = dataset[i][3]\n",
    "        x = x * 1e6\n",
    "        x = x.flatten()\n",
    "        y = y * 1e6\n",
    "        y = y.flatten()\n",
    "        z = z * 1e6\n",
    "        z = z * 0.7  # z scaling for immersion mismatch\n",
    "        z = z.flatten()\n",
    "        tid = tid.flatten()\n",
    "        tim = tim.flatten()\n",
    "        efo = efo.flatten()\n",
    "        track_ids = list(map(int, set(tid)))\n",
    "        track_ids.sort()\n",
    "        data_df = pd.DataFrame(columns=['tridx', 'tim0', 'x', 'y', 'z', 'tim', 'dt', 'efo'])\n",
    "        for track in track_ids[::]:\n",
    "            data_row = []\n",
    "            x_track = np.array([val for val,tr in zip(x,tid) if tr==track]).flatten()\n",
    "            y_track = np.array([val for val,tr in zip(y,tid) if tr==track]).flatten()\n",
    "            z_track = np.array([val for val,tr in zip(z,tid) if tr==track]).flatten()\n",
    "            z1_track = np.array([val for val,tr in zip(z1,tid) if tr==track]).flatten()\n",
    "            tim_track = np.array([val for val,tr in zip(tim,tid) if tr==track]).flatten()\n",
    "            efo_track = np.array([val for val,tr in zip(efo,tid) if tr==track]).flatten()\n",
    "            z_diff = z_track - z1_track[0]\n",
    "            data_row.append(track)\n",
    "            data_row.append(tim_track[0])\n",
    "            data_row.append(x_track)\n",
    "            data_row.append(y_track)\n",
    "            data_row.append(z_track)\n",
    "            tim_track = tim_track - tim_track[0]\n",
    "            data_row.append(tim_track)\n",
    "            data_row.append(np.diff(tim_track))\n",
    "            data_row.append(efo_track)\n",
    "            data_df = pd.concat([data_df, pd.DataFrame([data_row], columns=data_df.columns)], ignore_index=True)\n",
    "\n",
    "        # dt filtering of tracks - remove localizations with dt larger than threshold in a rolling window\n",
    "        data_df_clean = pd.DataFrame(columns=['tridx', 'tim0', 'x', 'y', 'z', 'sig', 'tim', 'dt', 'efo'])\n",
    "        trs = np.arange(0,len(data_df))\n",
    "        for tr in trs:\n",
    "            data_row = []\n",
    "            dt_track_full = np.array(data_df.iloc[tr]['dt'])*1e6\n",
    "            dt_track_full = np.insert(dt_track_full,0,0)\n",
    "            if len(dt_track_full) > window_pts:\n",
    "                local_dt_full = []\n",
    "                for i in np.arange(0, len(dt_track_full)):\n",
    "                    if i > int(window_pts/2) and i < len(dt_track_full)-int(window_pts/2)-1:\n",
    "                        local_dt_full.append(np.mean(dt_track_full[i-int(window_pts/2):i+int(window_pts/2)]))\n",
    "                    else:\n",
    "                        local_dt_full.append(np.nan)\n",
    "                local_dt_full = np.array(local_dt_full)\n",
    "                idx_lists = consecutive_bool(np.argwhere(local_dt_full<dt_loc_thresh).flatten())\n",
    "                # loop through all accepted tracks\n",
    "                for idx_list in idx_lists[:1]:\n",
    "                    dt_track = dt_track_full[idx_list]\n",
    "                    if len(dt_track) > len_lim:\n",
    "                        x_track = np.array(data_df.iloc[tr]['x'][idx_list]).flatten()\n",
    "                        y_track = np.array(data_df.iloc[tr]['y'][idx_list]).flatten()\n",
    "                        z_track = np.array(data_df.iloc[tr]['z'][idx_list]).flatten()\n",
    "                        sig_track = np.ones(np.shape(x_track))*10\n",
    "                        tim_track = np.array(data_df.iloc[tr]['tim'][idx_list]).flatten()\n",
    "                        efo_track = np.array(data_df.iloc[tr]['efo'][idx_list]).flatten()\n",
    "\n",
    "                        data_row.append(tr)\n",
    "                        data_row.append(tim_track[0])\n",
    "                        data_row.append(x_track)\n",
    "                        data_row.append(y_track)\n",
    "                        data_row.append(z_track)\n",
    "                        data_row.append(sig_track)\n",
    "                        tim_track = tim_track - tim_track[0]\n",
    "                        data_row.append(tim_track)\n",
    "                        data_row.append(np.diff(tim_track))\n",
    "                        data_row.append(efo_track)\n",
    "                        data_df_clean = pd.concat([data_df_clean, pd.DataFrame([data_row], columns=data_df_clean.columns)], ignore_index=True)\n",
    "                        \n",
    "        x = data_df_clean['x'].explode('x')\n",
    "        y = data_df_clean['y'].explode('y')\n",
    "        z = data_df_clean['z'].explode('z')\n",
    "        sig = data_df_clean['sig'].explode('sig')\n",
    "        t = data_df_clean['tim'].explode('tim')\n",
    "        dt = data_df_clean['dt'].explode('dt')\n",
    "        efo = data_df_clean['efo'].explode('efo')\n",
    "\n",
    "        data_clean = pd.DataFrame(columns=['id', 't', 'x', 'y', 'z', 'uncertainty_xy'])\n",
    "        data_clean['id'] = range(len(x))\n",
    "        data_clean['t'] = t\n",
    "        data_clean['x'] = x*1e3\n",
    "        data_clean['y'] = y*1e3\n",
    "        data_clean['z'] = z*1e3\n",
    "        data_clean['uncertainty_xy'] = sig\n",
    "        \n",
    "        data_clean.to_csv(os.path.join(topfolder,folder,savename),index=False,sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mfxdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
