{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import zipfile\n",
    "import optuna\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from peak_detection_bright import peak_detection_bright\n",
    "\n",
    "parentdir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_points_2d(pred_xy, gt_xy, dr=3.0):\n",
    "    \"\"\"\n",
    "    pred_xy, gt_xy: list/array of (x, y)\n",
    "    One-to-one greedy matching within dr.\n",
    "    Returns tp, fp, fn, matches=[(pred_j, gt_i), ...]\n",
    "    \"\"\"\n",
    "    pred = np.asarray(pred_xy, float)\n",
    "    gt   = np.asarray(gt_xy, float)\n",
    "\n",
    "    if pred.size == 0:\n",
    "        return 0, 0, len(gt), []\n",
    "    if gt.size == 0:\n",
    "        return 0, len(pred), 0, []\n",
    "\n",
    "    used_pred = set()\n",
    "    matches = []\n",
    "\n",
    "    for i in range(len(gt)):\n",
    "        x, y = gt[i]\n",
    "        best_j = None\n",
    "        best_d = None\n",
    "\n",
    "        for j in range(len(pred)):\n",
    "            if j in used_pred:\n",
    "                continue\n",
    "            d = np.hypot(pred[j, 0] - x, pred[j, 1] - y)\n",
    "            if d <= dr and (best_d is None or d < best_d):\n",
    "                best_d = d\n",
    "                best_j = j\n",
    "\n",
    "        if best_j is not None:\n",
    "            used_pred.add(best_j)\n",
    "            matches.append((best_j, i))\n",
    "\n",
    "    tp = len(matches)\n",
    "    fp = len(pred) - tp\n",
    "    fn = len(gt) - tp\n",
    "    return tp, fp, fn, matches\n",
    "\n",
    "def precision_recall_fbeta(tp, fp, fn, beta=1.0):\n",
    "    prec = 0.0 if (tp + fp) == 0 else tp / (tp + fp)\n",
    "    rec  = 0.0 if (tp + fn) == 0 else tp / (tp + fn)\n",
    "    b2 = beta * beta\n",
    "    denom = (1 + b2) * tp + b2 * fn + fp\n",
    "    fbeta = 0.0 if denom == 0 else (1 + b2) * tp / denom\n",
    "    return prec, rec, fbeta\n",
    "\n",
    "def run_peak_pipeline_single_frame(img, params):\n",
    "    \"\"\"\n",
    "    Replace THIS with your peak pipeline call.\n",
    "    Must return coords as (N,2) array in (x,y) order.\n",
    "    \"\"\"\n",
    "    coords, *_ = peak_detection_bright(img, prev_frames=None, binary_mask=None, exinfo=None, presetROIsize=True, **params)\n",
    "    if coords is None:\n",
    "        return np.empty((0, 2), dtype=float)\n",
    "    coords = np.asarray(coords)\n",
    "    if coords.size == 0:\n",
    "        return np.empty((0, 2), dtype=float)\n",
    "    return coords[:, :2].astype(float)\n",
    "\n",
    "def fbeta(tp, fp, fn, beta=2.0):\n",
    "    b2 = beta * beta\n",
    "    denom = (1 + b2) * tp + b2 * fn + fp\n",
    "    return 0.0 if denom == 0 else (1 + b2) * tp / denom\n",
    "\n",
    "def evaluate_params(conf_data, manual_events, cav_params, dr=5.0, beta=0.25):\n",
    "    pred_events = run_peak_pipeline_single_frame(conf_data, cav_params)\n",
    "    tp, fp, fn, matches = match_points_2d(pred_events, manual_events, dr=dr)\n",
    "    score = fbeta(tp, fp, fn, beta=beta)\n",
    "    return score, tp, fp, fn, pred_events, matches\n",
    "\n",
    "def load_manual_events_from_zip(folder, file):\n",
    "    \"\"\"\n",
    "    Returns sorted list of (frame, x, y) as ints.\n",
    "    \"\"\"\n",
    "    roinames = zipfile.ZipFile(os.path.join(folder,file)).namelist()\n",
    "    manual_events = []\n",
    "    for roiname in roinames:\n",
    "        y = int(roiname.split('-')[0].split('.')[0])\n",
    "        x = int(roiname.split('-')[1].split('.')[0])\n",
    "        manual_events.append((x, y))\n",
    "    manual_events.sort(key=lambda v: v[0])\n",
    "    return manual_events\n",
    "\n",
    "def optimize_single_frame(img, manual_xy, dr=3.0, beta=1.0, n_trials=200, seed=0):\n",
    "    \"\"\"\n",
    "    img: 2D numpy array\n",
    "    manual_xy: list of (x,y)\n",
    "    \"\"\"\n",
    "    sampler = optuna.samplers.TPESampler(seed=seed)\n",
    "    study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "\n",
    "    def objective(trial):\n",
    "        # Suggest parameters (edit ranges to match your pipeline)\n",
    "        params = dict(\n",
    "            maxfilter_kersize=trial.suggest_float(\"maxfilter_kersize\", 5.0, 5.0),\n",
    "            peak_min_dist=trial.suggest_float(\"peak_min_dist\", 5.0, 20.0),\n",
    "            num_peaks=trial.suggest_int(\"num_peaks\", 200, 200),\n",
    "            thresh_abs=trial.suggest_float(\"thresh_abs\", 5.0, 100.0),\n",
    "            smoothing_radius=trial.suggest_float(\"smoothing_radius\", 0.5, 2.0),\n",
    "            border_limit=trial.suggest_int(\"border_limit\", 15, 15),\n",
    "            init_smooth=trial.suggest_int(\"init_smooth\", 1, 1),\n",
    "            roi_border=trial.suggest_int(\"roi_border\", 5, 5),\n",
    "            roi_th_factor=trial.suggest_int(\"roi_th_factor\", 6, 6),\n",
    "        )\n",
    "        # Constraints\n",
    "        pred = run_peak_pipeline_single_frame(img, params)\n",
    "        pred_xy = [(float(x), float(y)) for x, y in pred]  # ensure list of tuples\n",
    "\n",
    "        tp, fp, fn, _ = match_points_2d(pred_xy, manual_xy, dr=dr)\n",
    "        prec, rec, f = precision_recall_fbeta(tp, fp, fn, beta=beta)\n",
    "\n",
    "        # Log extra info\n",
    "        trial.set_user_attr(\"tp\", int(tp))\n",
    "        trial.set_user_attr(\"fp\", int(fp))\n",
    "        trial.set_user_attr(\"fn\", int(fn))\n",
    "        trial.set_user_attr(\"precision\", float(prec))\n",
    "        trial.set_user_attr(\"recall\", float(rec))\n",
    "\n",
    "        return f\n",
    "\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    return study\n",
    "\n",
    "def load_conf_frame(folder, timelapse, frameidx=0):\n",
    "    files_all = os.listdir(folder)\n",
    "    files_conf = [f for f in files_all if \"conftimelapse\" in f and f.endswith(\".tif\") and 'temporal' not in f]\n",
    "    files_conf.sort()\n",
    "    file_conf = files_conf[timelapse]\n",
    "\n",
    "    conf_data = tiff.imread(os.path.join(folder, file_conf)) - 2**15\n",
    "    conf_data = conf_data[frameidx]\n",
    "    return conf_data, file_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [os.path.join(parentdir, 'exampledata\\\\cav1\\\\conftimelapse')]\n",
    "folderidx = 0\n",
    "folder = folders[folderidx]\n",
    "timelapse = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 0.25  # >1: recall, <1: precision; good balance in this case: ~0.25, i.e. precision four times as important as recall (avoid false positives, as we have many events, but do not want to get many false positives)\n",
    "dr = 5\n",
    "n_trials = 100\n",
    "\n",
    "conf_data, file_conf = load_conf_frame(folder, timelapse)\n",
    "print(\"Loaded:\", file_conf, \"shape:\", conf_data.shape)\n",
    "\n",
    "allfiles = os.listdir(folder)\n",
    "manualeventsfiles = [file for file in allfiles if 'manualevents' in file]\n",
    "manual_events = load_manual_events_from_zip(folder, file=manualeventsfiles[timelapse])\n",
    "print(\"Manual events:\", len(manual_events))\n",
    "\n",
    "study = optimize_single_frame(conf_data, manual_events, dr=dr, beta=beta, n_trials=n_trials, seed=0)\n",
    "print(\"Best FÎ²:\", study.best_value)\n",
    "print(\"Best params:\", study.best_params)\n",
    "\n",
    "best_params = study.best_params\n",
    "score, tp, fp, fn, pred_events, matches = evaluate_params(\n",
    "    conf_data, manual_events, best_params, dr=dr, beta=beta\n",
    ")\n",
    "print(f\"\\nBest F2={score:.4f}  TP={tp}  FP={fp}  FN={fn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mfxdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
