{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import zipfile\n",
    "import optuna\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from dyn_signalrise import dyn_signalrise\n",
    "\n",
    "parentdir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_events(pred, gt, dt=2, dr=3.0):\n",
    "    \"\"\"\n",
    "    pred, gt: arrays/list of (frame, x, y)\n",
    "    returns tp, fp, fn and matched index pairs\n",
    "    \"\"\"\n",
    "    pred = np.asarray(pred, float)\n",
    "    gt   = np.asarray(gt, float)\n",
    "\n",
    "    if len(pred) == 0:\n",
    "        return 0, 0, len(gt), []\n",
    "    if len(gt) == 0:\n",
    "        return 0, len(pred), 0, []\n",
    "\n",
    "    used_pred = set()\n",
    "    matches = []\n",
    "\n",
    "    # sort by time helps stability\n",
    "    gt_idx = np.argsort(gt[:, 0])\n",
    "    pred_idx = np.argsort(pred[:, 0])\n",
    "\n",
    "    for i in gt_idx:\n",
    "        t, x, y = gt[i]\n",
    "        best_j = None\n",
    "        best_cost = None\n",
    "\n",
    "        for j in pred_idx:\n",
    "            if j in used_pred:\n",
    "                continue\n",
    "            th, xh, yh = pred[j]\n",
    "            if abs(th - t) > dt:\n",
    "                continue\n",
    "            d = np.hypot(xh - x, yh - y)\n",
    "            if d > dr:\n",
    "                continue\n",
    "            cost = abs(th - t) + 0.01 * d  # mostly time, slightly space\n",
    "            if best_cost is None or cost < best_cost:\n",
    "                best_cost = cost\n",
    "                best_j = j\n",
    "\n",
    "        if best_j is not None:\n",
    "            used_pred.add(best_j)\n",
    "            matches.append((best_j, i))\n",
    "\n",
    "    tp = len(matches)\n",
    "    fp = len(pred) - tp\n",
    "    fn = len(gt) - tp\n",
    "    return tp, fp, fn, matches\n",
    "\n",
    "def fbeta(tp, fp, fn, beta=2.0):\n",
    "    b2 = beta * beta\n",
    "    denom = (1 + b2) * tp + b2 * fn + fp\n",
    "    return 0.0 if denom == 0 else (1 + b2) * tp / denom\n",
    "\n",
    "def load_manual_events_from_zip(folder, file):\n",
    "    roinames = zipfile.ZipFile(os.path.join(folder,file)).namelist()\n",
    "    manual_events = []\n",
    "    for roiname in roinames:\n",
    "        frame = int(roiname.split('-')[0])\n",
    "        y = int(roiname.split('-')[1].split('.')[0])\n",
    "        x = int(roiname.split('-')[2].split('.')[0])\n",
    "        manual_events.append((frame, x, y))\n",
    "    manual_events.sort(key=lambda v: v[0])\n",
    "    return manual_events\n",
    "\n",
    "def run_dyn_pipeline_on_stack(conf_data, dyn_params, warmup_frames=10):\n",
    "    \"\"\"\n",
    "    Runs dyn_signalrise sequentially across conf_data.\n",
    "    Returns list of predicted events (frame, x, y).\n",
    "    \"\"\"\n",
    "    tracks_all = None  # this is your exinfo state passed back in\n",
    "    pred_events = []\n",
    "\n",
    "    # we also need prev_frames for intensity ratio logic\n",
    "    frames_appear = int(dyn_params[\"frames_appear\"])\n",
    "\n",
    "    for idx, img_conf in enumerate(conf_data):\n",
    "        if idx <= warmup_frames:\n",
    "            # build state gradually\n",
    "            continue\n",
    "\n",
    "        # dyn_signalrise expects prev_frames to include at least ~2*frames_appear frames\n",
    "        start = max(0, idx - frames_appear * 2 - 2)\n",
    "        prev_frames = conf_data[start:idx]\n",
    "\n",
    "        coords_events, _, tracks_all, _ = dyn_signalrise(\n",
    "            img_ch1=img_conf,\n",
    "            prev_frames=prev_frames,\n",
    "            binary_mask=None,\n",
    "            exinfo=tracks_all,\n",
    "            presetROIsize=None,\n",
    "            # pipeline parameters:\n",
    "            min_dist=dyn_params[\"min_dist\"],\n",
    "            num_peaks=dyn_params[\"num_peaks\"],\n",
    "            thresh_abs_lo=dyn_params[\"thresh_abs_lo\"],\n",
    "            thresh_abs_hi=dyn_params[\"thresh_abs_hi\"],\n",
    "            border_limit=dyn_params[\"border_limit\"],\n",
    "            memory_frames=dyn_params[\"memory_frames\"],\n",
    "            track_search_dist=dyn_params[\"track_search_dist\"],\n",
    "            frames_appear=dyn_params[\"frames_appear\"],\n",
    "            thresh_intincratio=dyn_params[\"thresh_intincratio\"],\n",
    "            thresh_intincratio_max=dyn_params[\"thresh_intincratio_max\"],\n",
    "            thresh_move_dist=dyn_params[\"thresh_move_dist\"],\n",
    "        )\n",
    "\n",
    "        if coords_events is not None and coords_events.size > 0:\n",
    "            # You used coords_events[0] and stored (idx, x, y)\n",
    "            x = int(coords_events[0, 0])\n",
    "            y = int(coords_events[0, 1])\n",
    "            pred_events.append((idx, x, y))\n",
    "\n",
    "    return pred_events\n",
    "\n",
    "def dedupe_events_greedy(events, merge_dt=10, merge_dr=6.0, keep=\"earliest\"):\n",
    "    \"\"\"\n",
    "    Deduplicate event predictions by merging events that are close in time and space.\n",
    "    Returns: deduped_events (same tuple format as input, but reduced)\n",
    "    \"\"\"\n",
    "    if not events:\n",
    "        return []\n",
    "\n",
    "    events = list(events)\n",
    "    # sort by time\n",
    "    events.sort(key=lambda e: e[0])\n",
    "\n",
    "    clusters = []  # each cluster: list of events\n",
    "\n",
    "    for e in events:\n",
    "        t, x, y = e[0], e[1], e[2]\n",
    "\n",
    "        assigned = False\n",
    "        # try to assign to an existing cluster (typically only last few matter)\n",
    "        for c in reversed(clusters):\n",
    "            # representative: last kept event in cluster (or centroid)\n",
    "            rep = c[-1]\n",
    "            tr, xr, yr = rep[0], rep[1], rep[2]\n",
    "\n",
    "            if abs(t - tr) <= merge_dt and np.hypot(x - xr, y - yr) <= merge_dr:\n",
    "                c.append(e)\n",
    "                assigned = True\n",
    "                break\n",
    "\n",
    "            # because clusters are time-sorted, if we're too far in time, we can stop\n",
    "            if t - tr > merge_dt:\n",
    "                break\n",
    "\n",
    "        if not assigned:\n",
    "            clusters.append([e])\n",
    "\n",
    "    # choose representative per cluster\n",
    "    deduped = []\n",
    "    for c in clusters:\n",
    "        if keep == \"earliest\":\n",
    "            rep = min(c, key=lambda e: e[0])\n",
    "        elif keep == \"latest\":\n",
    "            rep = max(c, key=lambda e: e[0])\n",
    "        elif keep == \"mean\":\n",
    "            # average frame,x,y; if you have score as 4th entry, ignore it\n",
    "            arr = np.array([e[:3] for e in c], float)\n",
    "            t_mean, x_mean, y_mean = arr.mean(axis=0)\n",
    "            rep = (int(round(t_mean)), float(x_mean), float(y_mean))\n",
    "        else:\n",
    "            raise ValueError(\"keep must be 'earliest', 'latest', or 'mean'\")\n",
    "        deduped.append(rep)\n",
    "\n",
    "    # keep time order\n",
    "    deduped.sort(key=lambda e: e[0])\n",
    "    return deduped\n",
    "\n",
    "def evaluate_params(conf_data, manual_events, dyn_params, dt=30, dr=6.0, beta=2.0):\n",
    "    pred_events = run_dyn_pipeline_on_stack(conf_data, dyn_params, warmup_frames=10)\n",
    "    pred_events = dedupe_events_greedy(pred_events, merge_dt=dt, merge_dr=dr, keep='earliest')\n",
    "    tp, fp, fn, matches = match_events(pred_events, manual_events, dt=dt, dr=dr)\n",
    "    score = fbeta(tp, fp, fn, beta=beta)\n",
    "    return score, tp, fp, fn, pred_events, matches\n",
    "\n",
    "def load_conf_stack(folder, timelapse, analysis_stack_len):\n",
    "    files_all = os.listdir(folder)\n",
    "    files_conf = [f for f in files_all if \"conftimelapse\" in f and f.endswith(\".tif\")]\n",
    "    files_conf.sort()\n",
    "    file_conf = files_conf[timelapse]\n",
    "\n",
    "    conf_data = tiff.imread(os.path.join(folder, file_conf)) - 2**15\n",
    "    conf_data = conf_data[:analysis_stack_len]\n",
    "    return conf_data, file_conf\n",
    "\n",
    "def optimize_with_optuna(conf_data, manual_events, n_trials=100, dt=30, dr=6.0, beta=0.5, seed=0):\n",
    "    \"\"\"\n",
    "    Bayesian optimization over dyn_signalrise parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    sampler = optuna.samplers.TPESampler(seed=seed)\n",
    "\n",
    "    def objective(trial):\n",
    "        # Suggest parameters (adjust ranges to your microscope / SNR)\n",
    "        dyn_params = dict(\n",
    "            min_dist=trial.suggest_float(\"min_dist\", 1.0, 2.0),\n",
    "            num_peaks=trial.suggest_int(\"num_peaks\", 1000, 1000),\n",
    "            thresh_abs_lo=trial.suggest_float(\"thresh_abs_lo\", 0.4, 1.3),\n",
    "            thresh_abs_hi=trial.suggest_float(\"thresh_abs_hi\", 10.0, 35.0),\n",
    "            border_limit=trial.suggest_int(\"border_limit\", 4, 4),\n",
    "            memory_frames=trial.suggest_int(\"memory_frames\", 3, 10),\n",
    "            track_search_dist=trial.suggest_int(\"track_search_dist\", 4, 8),\n",
    "            frames_appear=trial.suggest_int(\"frames_appear\", 4, 10),\n",
    "            thresh_intincratio=trial.suggest_float(\"thresh_intincratio\", 1.05, 1.3),\n",
    "            thresh_intincratio_max=trial.suggest_float(\"thresh_intincratio_max\", 3.8, 4.5),\n",
    "            thresh_move_dist=trial.suggest_float(\"thresh_move_dist\", 0.9, 1.5),\n",
    "        )\n",
    "\n",
    "        # Hard constraints (prune invalid combos)\n",
    "        if dyn_params[\"thresh_abs_hi\"] <= dyn_params[\"thresh_abs_lo\"]:\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "        if dyn_params[\"thresh_intincratio_max\"] <= dyn_params[\"thresh_intincratio\"]:\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "        score, tp, fp, fn, _, _ = evaluate_params(\n",
    "            conf_data=conf_data,\n",
    "            manual_events=manual_events,\n",
    "            dyn_params=dyn_params,\n",
    "            dt=dt, dr=dr, beta=beta\n",
    "        )\n",
    "\n",
    "        # Log useful diagnostics\n",
    "        trial.set_user_attr(\"tp\", int(tp))\n",
    "        trial.set_user_attr(\"fp\", int(fp))\n",
    "        trial.set_user_attr(\"fn\", int(fn))\n",
    "\n",
    "        return score\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "    return study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [os.path.join(parentdir, 'exampledata\\\\dyn1\\\\conftimelapse')]\n",
    "folderidx = 0\n",
    "folder = folders[folderidx]\n",
    "timelapse = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_stack_len = 200  # 251210: 0: 200, 1: 300, 2: 300; 251209: 0: 100, 1: 100, 2: 200, 3: 200, 4: 200\n",
    "beta = 0.25  # >1: recall, <1: precision; good balance in this case: ~0.25, i.e. precision four times as important as recall (avoid false positives, as we have many events, but do not want to get many false positives)\n",
    "dr = 6\n",
    "dt = 40\n",
    "n_trials = 100\n",
    "\n",
    "conf_data, file_conf = load_conf_stack(folder, timelapse, analysis_stack_len)\n",
    "print(\"Loaded:\", file_conf, \"frames:\", conf_data.shape[0], \"shape:\", conf_data[0].shape)\n",
    "\n",
    "allfiles = os.listdir(folder)\n",
    "manualeventsfiles = [file for file in allfiles if 'manualevents' in file]\n",
    "manual_events = load_manual_events_from_zip(folder, file=manualeventsfiles[timelapse])\n",
    "print(\"Manual events:\", len(manual_events))\n",
    "\n",
    "# quick single evaluation (sanity check)\n",
    "dyn_params = dict(\n",
    "  min_dist= 1.5,\n",
    "  num_peaks= 1000,\n",
    "  thresh_abs_lo= 0.8,\n",
    "  thresh_abs_hi= 35.0,\n",
    "  border_limit= 4,\n",
    "  memory_frames= 7,\n",
    "  track_search_dist= 6,\n",
    "  frames_appear= 6,\n",
    "  thresh_intincratio= 1.1,\n",
    "  thresh_intincratio_max= 5.0,\n",
    "  thresh_move_dist= 1.3\n",
    ")\n",
    "\n",
    "score, tp, fp, fn, pred_events, matches = evaluate_params(\n",
    "    conf_data, manual_events, dyn_params, dt=dt, dr=dr, beta=beta\n",
    ")\n",
    "print(f\"Baseline F2={score:.4f}  TP={tp}  FP={fp}  FN={fn}\")\n",
    "\n",
    "# optimize\n",
    "study = optimize_with_optuna(\n",
    "    conf_data, manual_events,\n",
    "    n_trials=n_trials, dt=dt, dr=dr, beta=beta, seed=0\n",
    ")\n",
    "\n",
    "print(\"\\nBest score:\", study.best_value)\n",
    "print(\"Best params:\")\n",
    "for k, v in study.best_params.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "# evaluate best params once more (get events/matches)\n",
    "best_params = study.best_params\n",
    "score, tp, fp, fn, pred_events, matches = evaluate_params(\n",
    "    conf_data, manual_events, best_params, dt=dt, dr=dr, beta=beta\n",
    ")\n",
    "print(f\"\\nBest F2={score:.4f}  TP={tp}  FP={fp}  FN={fn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mfxdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
