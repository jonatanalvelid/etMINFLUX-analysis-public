{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import zipfile\n",
    "import optuna\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from gag_signalrise import gag_signalrise\n",
    "\n",
    "parentdir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_events(pred, gt, dt=2, dr=3.0):\n",
    "    \"\"\"\n",
    "    pred, gt: arrays/list of (frame, x, y)\n",
    "    returns tp, fp, fn and matched index pairs\n",
    "    \"\"\"\n",
    "    pred = np.asarray(pred, float)\n",
    "    gt   = np.asarray(gt, float)\n",
    "\n",
    "    if len(pred) == 0:\n",
    "        return 0, 0, len(gt), []\n",
    "    if len(gt) == 0:\n",
    "        return 0, len(pred), 0, []\n",
    "\n",
    "    used_pred = set()\n",
    "    matches = []\n",
    "\n",
    "    # sort by time helps stability\n",
    "    gt_idx = np.argsort(gt[:, 0])\n",
    "    pred_idx = np.argsort(pred[:, 0])\n",
    "\n",
    "    for i in gt_idx:\n",
    "        t, x, y = gt[i]\n",
    "        best_j = None\n",
    "        best_cost = None\n",
    "\n",
    "        for j in pred_idx:\n",
    "            if j in used_pred:\n",
    "                continue\n",
    "            th, xh, yh = pred[j]\n",
    "            if abs(th - t) > dt:\n",
    "                continue\n",
    "            d = np.hypot(xh - x, yh - y)\n",
    "            if d > dr:\n",
    "                continue\n",
    "            cost = abs(th - t) + 0.01 * d  # mostly time, slightly space\n",
    "            if best_cost is None or cost < best_cost:\n",
    "                best_cost = cost\n",
    "                best_j = j\n",
    "\n",
    "        if best_j is not None:\n",
    "            used_pred.add(best_j)\n",
    "            matches.append((best_j, i))\n",
    "\n",
    "    tp = len(matches)\n",
    "    fp = len(pred) - tp\n",
    "    fn = len(gt) - tp\n",
    "    return tp, fp, fn, matches\n",
    "\n",
    "def fbeta(tp, fp, fn, beta=2.0):\n",
    "    b2 = beta * beta\n",
    "    denom = (1 + b2) * tp + b2 * fn + fp\n",
    "    return 0.0 if denom == 0 else (1 + b2) * tp / denom\n",
    "\n",
    "def load_manual_events_from_zip(folder, file):\n",
    "    \"\"\"\n",
    "    Your file naming convention:\n",
    "      roiname like: \"<frame>-<x>.<ext?>-<y>.<ext?>\" (based on your parsing)\n",
    "    You currently do:\n",
    "      frame = roiname.split('-')[0]\n",
    "      x     = roiname.split('-')[2].split('.')[0]\n",
    "      y     = roiname.split('-')[1].split('.')[0]\n",
    "    Returns sorted list of (frame, x, y) as ints.\n",
    "    \"\"\"\n",
    "    roinames = zipfile.ZipFile(os.path.join(folder,file)).namelist()\n",
    "    manual_events = []\n",
    "    for roiname in roinames:\n",
    "        frame = int(roiname.split('-')[0])\n",
    "        y = int(roiname.split('-')[1].split('.')[0])\n",
    "        x = int(roiname.split('-')[2].split('.')[0])\n",
    "        manual_events.append((frame, x, y))\n",
    "    manual_events.sort(key=lambda v: v[0])\n",
    "    return manual_events\n",
    "\n",
    "def run_gag_pipeline_on_stack(conf_data, gag_params, warmup_frames=10):\n",
    "    \"\"\"\n",
    "    Runs gag_signalrise sequentially across conf_data.\n",
    "    Returns list of predicted events (frame, x, y).\n",
    "\n",
    "    gag_params: dict of keyword args for gag_signalrise (min_dist, num_peaks, etc.)\n",
    "    \"\"\"\n",
    "    tracks_all = None  # this is your exinfo state passed back in\n",
    "    pred_events = []\n",
    "\n",
    "    # we also need prev_frames for intensity ratio logic\n",
    "    frames_appear = int(gag_params[\"frames_appear\"])\n",
    "\n",
    "    for idx, img_conf in enumerate(conf_data):\n",
    "        if idx <= warmup_frames:\n",
    "            # build state gradually\n",
    "            continue\n",
    "\n",
    "        # gag_signalrise expects prev_frames to include at least ~2*frames_appear frames\n",
    "        start = max(0, idx - frames_appear * 2 - 2)\n",
    "        prev_frames = conf_data[start:idx]\n",
    "\n",
    "        coords_events, _, tracks_all, _ = gag_signalrise(\n",
    "            img_ch1=img_conf,\n",
    "            prev_frames=prev_frames,\n",
    "            binary_mask=None,\n",
    "            exinfo=tracks_all,\n",
    "            presetROIsize=None,\n",
    "            # pipeline parameters:\n",
    "            min_dist_appear=gag_params[\"min_dist_appear\"],\n",
    "            num_peaks=gag_params[\"num_peaks\"],\n",
    "            thresh_abs_lo=gag_params[\"thresh_abs_lo\"],\n",
    "            thresh_abs_hi=gag_params[\"thresh_abs_hi\"],\n",
    "            finalintlo=gag_params[\"finalintlo\"],\n",
    "            finalinthi=gag_params[\"finalinthi\"],\n",
    "            border_limit=gag_params[\"border_limit\"],\n",
    "            memory_frames=gag_params[\"memory_frames\"],\n",
    "            track_search_dist=gag_params[\"track_search_dist\"],\n",
    "            frames_appear=gag_params[\"frames_appear\"],\n",
    "            thresh_intincratio=gag_params[\"thresh_intincratio\"],\n",
    "            thresh_intincratio_max=gag_params[\"thresh_intincratio_max\"],\n",
    "            intincslope=gag_params[\"intincslope\"],\n",
    "            thresh_move_dist=gag_params[\"thresh_move_dist\"],\n",
    "        )\n",
    "\n",
    "        if coords_events is not None and coords_events.size > 0:\n",
    "            # You used coords_events[0] and stored (idx, x, y)\n",
    "            x = int(coords_events[0, 0])\n",
    "            y = int(coords_events[0, 1])\n",
    "            pred_events.append((idx, x, y))\n",
    "\n",
    "    return pred_events\n",
    "\n",
    "def dedupe_events_greedy(events, merge_dt=10, merge_dr=6.0, keep=\"earliest\"):\n",
    "    \"\"\"\n",
    "    Deduplicate event predictions by merging events that are close in time and space.\n",
    "    \n",
    "    events: list of (frame, x, y) or (frame, x, y, score)\n",
    "    merge_dt: max time difference (frames) to merge\n",
    "    merge_dr: max spatial distance (pixels) to merge\n",
    "    keep: \"earliest\" | \"latest\" | \"mean\"\n",
    "    \n",
    "    Returns: deduped_events (same tuple format as input, but reduced)\n",
    "    \"\"\"\n",
    "    if not events:\n",
    "        return []\n",
    "\n",
    "    events = list(events)\n",
    "    # sort by time\n",
    "    events.sort(key=lambda e: e[0])\n",
    "\n",
    "    clusters = []  # each cluster: list of events\n",
    "\n",
    "    for e in events:\n",
    "        t, x, y = e[0], e[1], e[2]\n",
    "\n",
    "        assigned = False\n",
    "        # try to assign to an existing cluster (typically only last few matter)\n",
    "        for c in reversed(clusters):\n",
    "            # representative: last kept event in cluster (or centroid)\n",
    "            rep = c[-1]\n",
    "            tr, xr, yr = rep[0], rep[1], rep[2]\n",
    "\n",
    "            if abs(t - tr) <= merge_dt and np.hypot(x - xr, y - yr) <= merge_dr:\n",
    "                c.append(e)\n",
    "                assigned = True\n",
    "                break\n",
    "\n",
    "            # because clusters are time-sorted, if we're too far in time, we can stop\n",
    "            if t - tr > merge_dt:\n",
    "                break\n",
    "\n",
    "        if not assigned:\n",
    "            clusters.append([e])\n",
    "\n",
    "    # choose representative per cluster\n",
    "    deduped = []\n",
    "    for c in clusters:\n",
    "        if keep == \"earliest\":\n",
    "            rep = min(c, key=lambda e: e[0])\n",
    "        elif keep == \"latest\":\n",
    "            rep = max(c, key=lambda e: e[0])\n",
    "        elif keep == \"mean\":\n",
    "            # average frame,x,y; if you have score as 4th entry, ignore it\n",
    "            arr = np.array([e[:3] for e in c], float)\n",
    "            t_mean, x_mean, y_mean = arr.mean(axis=0)\n",
    "            rep = (int(round(t_mean)), float(x_mean), float(y_mean))\n",
    "        else:\n",
    "            raise ValueError(\"keep must be 'earliest', 'latest', or 'mean'\")\n",
    "        deduped.append(rep)\n",
    "\n",
    "    # keep time order\n",
    "    deduped.sort(key=lambda e: e[0])\n",
    "    return deduped\n",
    "\n",
    "def evaluate_params(conf_data, manual_events, gag_params, dt=30, dr=6.0, beta=2.0):\n",
    "    pred_events = run_gag_pipeline_on_stack(conf_data, gag_params, warmup_frames=10)\n",
    "    pred_events = dedupe_events_greedy(pred_events, merge_dt=dt, merge_dr=dr, keep='earliest')\n",
    "    tp, fp, fn, matches = match_events(pred_events, manual_events, dt=dt, dr=dr)\n",
    "    score = fbeta(tp, fp, fn, beta=beta)\n",
    "    return score, tp, fp, fn, pred_events, matches\n",
    "\n",
    "def load_conf_stack(folder, timelapse, analysis_stack_len):\n",
    "    files_all = os.listdir(folder)\n",
    "    files_conf = [f for f in files_all if \"conftimelapse\" in f and f.endswith(\".tif\")]\n",
    "    files_conf.sort()\n",
    "    file_conf = files_conf[timelapse]\n",
    "\n",
    "    conf_data = tiff.imread(os.path.join(folder, file_conf)) - 2**15\n",
    "    conf_data = conf_data[:analysis_stack_len]\n",
    "    return conf_data, file_conf\n",
    "\n",
    "def optimize_with_optuna(conf_data, manual_events, n_trials=100, dt=30, dr=6.0, beta=0.5, seed=0):\n",
    "    \"\"\"\n",
    "    Bayesian optimization over gag_signalrise parameters.\n",
    "\n",
    "    Tip: start with n_trials=50-100 to find good regions, then 200-500.\n",
    "    \n",
    "    min_dist=1.0,\n",
    "    num_peaks=1000,\n",
    "    thresh_abs_lo=1.2,\n",
    "    thresh_abs_hi=10.0,\n",
    "    border_limit=10,\n",
    "    memory_frames=10,\n",
    "    track_search_dist=6,\n",
    "    frames_appear=6,\n",
    "    thresh_intincratio=1.2,\n",
    "    thresh_intincratio_max=8.0,\n",
    "    thresh_move_dist=1.5,\n",
    "    \"\"\"\n",
    "\n",
    "    sampler = optuna.samplers.TPESampler(seed=seed)\n",
    "\n",
    "    def objective(trial):\n",
    "        # Suggest parameters (adjust ranges to your microscope / SNR)\n",
    "\n",
    "        gag_params = dict(\n",
    "            min_dist_appear=trial.suggest_float(\"min_dist_appear\", 1.0, 7.0),\n",
    "            num_peaks=trial.suggest_int(\"num_peaks\", 200, 200),\n",
    "            thresh_abs_lo=trial.suggest_float(\"thresh_abs_lo\", 1.0, 6.0),\n",
    "            thresh_abs_hi=trial.suggest_float(\"thresh_abs_hi\", 10.0, 70.0),\n",
    "            finalintlo=trial.suggest_float(\"finalintlo\", 0.65, 1.25),\n",
    "            finalinthi=trial.suggest_float(\"finalinthi\", 3.0, 70.0),\n",
    "            border_limit=trial.suggest_int(\"border_limit\", 5, 5),\n",
    "            memory_frames=trial.suggest_int(\"memory_frames\", 2, 5),\n",
    "            track_search_dist=trial.suggest_float(\"track_search_dist\", 2.0, 6.0),\n",
    "            frames_appear=trial.suggest_int(\"frames_appear\", 3, 8),\n",
    "            thresh_intincratio=trial.suggest_float(\"thresh_intincratio\", 1.05, 1.55),\n",
    "            thresh_intincratio_max=trial.suggest_float(\"thresh_intincratio_max\", 4.0, 30.0),\n",
    "            intincslope=trial.suggest_float(\"intincslope\", 0.02, 0.2),\n",
    "            thresh_move_dist=trial.suggest_float(\"thresh_move_dist\", 0.5, 2.0),\n",
    "        )\n",
    "\n",
    "        # Hard constraints (prune invalid combos)\n",
    "        if gag_params[\"thresh_abs_hi\"] <= gag_params[\"thresh_abs_lo\"]:\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "        if gag_params[\"thresh_intincratio_max\"] <= gag_params[\"thresh_intincratio\"]:\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "        score, tp, fp, fn, _, _ = evaluate_params(\n",
    "            conf_data=conf_data,\n",
    "            manual_events=manual_events,\n",
    "            gag_params=gag_params,\n",
    "            dt=dt, dr=dr, beta=beta\n",
    "        )\n",
    "\n",
    "        # Log useful diagnostics\n",
    "        trial.set_user_attr(\"tp\", int(tp))\n",
    "        trial.set_user_attr(\"fp\", int(fp))\n",
    "        trial.set_user_attr(\"fn\", int(fn))\n",
    "\n",
    "        return score\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "    return study\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def tile_boxes(H, W, tile_h=128, tile_w=128, overlap=16):\n",
    "    \"\"\"\n",
    "    Generate (x0, x1, y0, y1) tiles covering an HxW image with overlap.\n",
    "    overlap is in pixels on each step (i.e. stride = tile - overlap).\n",
    "    \"\"\"\n",
    "    stride_y = max(1, tile_h - overlap)\n",
    "    stride_x = max(1, tile_w - overlap)\n",
    "\n",
    "    boxes = []\n",
    "    for y0 in range(0, H, stride_y):\n",
    "        y1 = min(y0 + tile_h, H)\n",
    "        y0 = max(0, y1 - tile_h)  # shift back so tile is full-size if near border\n",
    "\n",
    "        for x0 in range(0, W, stride_x):\n",
    "            x1 = min(x0 + tile_w, W)\n",
    "            x0 = max(0, x1 - tile_w)\n",
    "\n",
    "            boxes.append((x0, x1, y0, y1))\n",
    "\n",
    "    # remove duplicates (can happen near borders)\n",
    "    boxes = list(dict.fromkeys(boxes))\n",
    "    return boxes\n",
    "\n",
    "def crop_stack(conf_data, box):\n",
    "    \"\"\"\n",
    "    conf_data: (T, H, W)\n",
    "    box: (x0, x1, y0, y1)\n",
    "    returns cropped stack view/copy\n",
    "    \"\"\"\n",
    "    x0, x1, y0, y1 = box\n",
    "    return conf_data[:, y0:y1, x0:x1]\n",
    "\n",
    "def remap_events_to_box(events, box):\n",
    "    \"\"\"\n",
    "    events: list of (frame, x, y)\n",
    "    box: (x0, x1, y0, y1)\n",
    "    returns list of (frame, x_local, y_local) for events inside the box\n",
    "    \"\"\"\n",
    "    x0, x1, y0, y1 = box\n",
    "    remapped = []\n",
    "    for (t, x, y) in events:\n",
    "        if (x0 <= x < x1) and (y0 <= y < y1):\n",
    "            remapped.append((t, x - x0, y - y0))\n",
    "    return remapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [os.path.join(parentdir, 'exampledata\\\\gag\\\\conftimelapse')]\n",
    "folderidx = 0\n",
    "folder = folders[folderidx]\n",
    "timelapse = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_stack_len = 100  # length of loaded confocal timelapse in frames\n",
    "beta = 3  # >1: recall, <1: precision; good balance in this case: ~3, i.e. recall three times as important as precision (avoid missing events, as we do not have many happening. MultiDetect-ROI follow - can always remove after finding).\n",
    "dr = 6\n",
    "dt = 40\n",
    "n_trials = 100\n",
    "\n",
    "analysis_stack_len \n",
    "conf_data, file_conf = load_conf_stack(folder, timelapse, analysis_stack_len)\n",
    "print(\"Loaded:\", file_conf, \"frames:\", conf_data.shape[0], \"shape:\", conf_data[0].shape)\n",
    "\n",
    "allfiles = os.listdir(folder)\n",
    "manualeventsfiles = [file for file in allfiles if 'manualevents' in file]\n",
    "manual_events = load_manual_events_from_zip(folder, file=manualeventsfiles[timelapse])\n",
    "print(\"Manual events:\", len(manual_events))\n",
    "\n",
    "# crop into tiles\n",
    "# conf_data shape: (T, H, W)\n",
    "T, H, W = conf_data.shape\n",
    "\n",
    "# choose tile size (tune this)\n",
    "tile_h, tile_w = 133, 133\n",
    "overlap = 15   # overlap helps avoid missing events on borders\n",
    "\n",
    "boxes = tile_boxes(H, W, tile_h=tile_h, tile_w=tile_w, overlap=overlap)  # get coordinates for crop boxes\n",
    "print(\"Num tiles:\", len(boxes))\n",
    "\n",
    "TP, FP, FN = 0, 0, 0\n",
    "# crop data and annotated events and take one tile\n",
    "for tile_idx, box in enumerate(boxes):\n",
    "    manual_events_tile = remap_events_to_box(manual_events, box)\n",
    "    if len(manual_events_tile) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        print(\"Tile index:\", tile_idx)\n",
    "    conf_tile = crop_stack(conf_data, box)\n",
    "\n",
    "    # optimize\n",
    "    study = optimize_with_optuna(\n",
    "        conf_tile, manual_events_tile,\n",
    "        n_trials=n_trials, dt=dt, dr=dr, beta=beta, seed=0\n",
    "    )\n",
    "\n",
    "    print(\"\\nBest score:\", study.best_value)\n",
    "    print(\"Best params:\")\n",
    "    for k, v in study.best_params.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "\n",
    "    # evaluate best params once more (get events/matches)\n",
    "    score, tp, fp, fn, pred_events, matches = evaluate_params(\n",
    "        conf_tile, manual_events_tile, study.best_params, dt=dt, dr=dr, beta=beta\n",
    "    )\n",
    "    print(f\"\\nBest F2={score:.4f}  TP={tp}  FP={fp}  FN={fn}\")\n",
    "    TP += tp\n",
    "    FP += fp\n",
    "    FN += fn\n",
    "    \n",
    "global_f = fbeta(TP, FP, FN, beta=beta)\n",
    "print(\"\\nGlobal fb score:\", global_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mfxdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
